{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c937ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dcb3661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35482.748157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12585.738855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10070.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27755.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37287.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46656.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58283.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count    407.000000\n",
       "mean   35482.748157\n",
       "std    12585.738855\n",
       "min    10070.590000\n",
       "25%    27755.580000\n",
       "50%    37287.160000\n",
       "75%    46656.325000\n",
       "max    58283.800000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Dataset/btc_data.txt', header=None)\n",
    "\n",
    "# Brief description of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9562c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegCostFunction(X, y, theta, Lambda):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take in numpy array of  data X, labels y and theta, to return the regularized cost function and gradients\n",
    "    of the linear regression model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of training examples \n",
    "    m = y.shape[0]\n",
    "    \n",
    "    #linear regression model\n",
    "    h = np.dot(X,theta)\n",
    "    \n",
    "    cost = 1/(2*m) * np.sum((h - y)**2)\n",
    "    reg_cost = cost + Lambda/(2*m) * (np.sum(theta[1:]**2))\n",
    "    \n",
    "    # compute the gradient\n",
    "    grad_0= (1/m) * np.dot(X.transpose(),(h - y))[0]\n",
    "    grad = (1/m) * np.dot(X.transpose(),(h - y))[1:] + (Lambda/m)* theta[1:]\n",
    "       \n",
    "    #  make the complete gradient a column vector\n",
    "    grad_all=np.append(grad_0,grad)\n",
    "    grad_all = grad_all.reshape((len(grad_all), 1))\n",
    "    \n",
    "    return reg_cost, grad_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ba314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize our data file according to the memory we want for our model\n",
    "def resize_data_file(columns):\n",
    "    ls = []\n",
    "    with open('../Dataset/btc_data.txt') as f:\n",
    "        for i in f.readlines():\n",
    "            ls.append(i.strip())\n",
    "\n",
    "    ls2 = []\n",
    "    for i in ls:\n",
    "        ls2.append(float(i))\n",
    "    count = 0\n",
    "    strr = ''\n",
    "    str_ls = []\n",
    "    \n",
    "    # Get the divider to normalize our data\n",
    "    max_num = int(max(ls2))\n",
    "    divider = 0\n",
    "    if max_num % 10000 == 0:\n",
    "        divider = max_num\n",
    "    else:\n",
    "        divider = 10000 - (max_num % 10000) + max_num\n",
    "\n",
    "    for i in ls2[:-(columns-1)]:\n",
    "        for j in range(columns):\n",
    "            if j == 0:\n",
    "                strr = str(ls2[count] / divider)\n",
    "            else:\n",
    "                strr = strr + ',' + str(ls2[count + j] / divider)\n",
    "        count += 1\n",
    "        str_ls.append(strr)\n",
    "    \n",
    "    # Divide the total data into training (60%), validation (20%) and testing (the last 20%)\n",
    "    training = round(len(str_ls) * 0.6)\n",
    "    validation = round(len(str_ls) * 0.2) + training\n",
    "\n",
    "    # Write the data with the correct number of columns into each file\n",
    "    with open('../Dataset/training_data.txt', 'w') as f:\n",
    "        for i in str_ls[:training]:\n",
    "            print(i, file=f)\n",
    "    \n",
    "    with open('../Dataset/validation_data.txt', 'w') as f:\n",
    "        for i in str_ls[training:validation]:\n",
    "            print(i, file=f)\n",
    "    \n",
    "    with open('../Dataset/testing_data.txt', 'w') as f:\n",
    "        for i in str_ls[validation:]:\n",
    "            print(i, file=f)\n",
    "            \n",
    "    return divider, len(str_ls[validation:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e84ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_diff_file(columns):\n",
    "    # Open the file with the price difference and save its data into a list\n",
    "    ls = []\n",
    "    with open('../Dataset/btc_data.txt') as f:\n",
    "        for i in f.readlines():\n",
    "            ls.append(float(i.strip()))\n",
    "\n",
    "    # Get the list of differences\n",
    "    diff_ls = getDiffData(ls)\n",
    "\n",
    "    # Variables\n",
    "    count = 0\n",
    "    strr = ''\n",
    "    str_ls = []\n",
    "    \n",
    "    # Normalize data\n",
    "    x_array = np.array(diff_ls)\n",
    "    arr = preprocessing.normalize([x_array], return_norm=True)\n",
    "\n",
    "    normalized_array = arr[0][0]\n",
    "    scalar_value = arr[1][0]\n",
    "    \n",
    "    # Divide the data in the correct number of columns\n",
    "    for i in normalized_array[:-(columns-1)]:\n",
    "        for j in range(columns):\n",
    "            if j == 0:\n",
    "                strr = str(normalized_array[count])\n",
    "            else:\n",
    "                strr = strr + ',' + str(normalized_array[count + j])\n",
    "        count += 1\n",
    "        str_ls.append(strr)\n",
    "\n",
    "    # Divide the total data into training (60%), validation (20%) and testing (the last 20%)\n",
    "    training = round(len(str_ls) * 0.6)\n",
    "    validation = round(len(str_ls) * 0.2) + training\n",
    "\n",
    "    # Write the data with the correct number of columns into each file\n",
    "    with open('../Dataset/training_diff.txt', 'w') as f:\n",
    "        for i in str_ls[:training]:\n",
    "            print(i, file=f)\n",
    "    \n",
    "    with open('../Dataset/validation_diff.txt', 'w') as f:\n",
    "        for i in str_ls[training:validation]:\n",
    "            print(i, file=f)\n",
    "    \n",
    "    with open('../Dataset/testing_diff.txt', 'w') as f:\n",
    "        for i in str_ls[validation:]:\n",
    "            print(i, file=f)\n",
    "            \n",
    "    \n",
    "    return scalar_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50143f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiffData(ls):\n",
    "    \n",
    "    # Variables\n",
    "    diff_ls = []\n",
    "    count = 1\n",
    "    \n",
    "    # Subtract each day to get the difference (p(1) - p(0), p(2) - p(1), ...) \n",
    "    # and save the differences in a list \n",
    "    for i in ls[:-1]:\n",
    "        diff = round(ls[count] - i, 2)\n",
    "        diff_ls.append(diff)\n",
    "        count += 1\n",
    "        \n",
    "    # Return the list of differences between prices\n",
    "    return diff_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79723af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationCurve (X, y, Xval, yval, learn_rate, num_iter):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the best lambda and the respective train and cross validation set errors\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    mval = Xval.shape[0]  # Number of validation examples \n",
    "    \n",
    "    error_train, error_val = [],[]\n",
    "    \n",
    "    theta_ini=np.zeros((n,1))\n",
    "    theta = gradientDescent( X, y,theta_ini,learn_rate,num_iter,0)[0]\n",
    "\n",
    "    #After the training is over, apply the trained model for train and validation data\n",
    "    pred_train = np.dot(X,theta)\n",
    "    pred_val = np.dot(Xval,theta)\n",
    "\n",
    "    #Compute the train and validation error\n",
    "    error_train_i = 1/(2*m) * np.sum((pred_train - y)**2)\n",
    "    error_val_i = 1/(2*mval) * np.sum((pred_val - yval)**2)\n",
    "\n",
    "    error_train.append(error_train_i)\n",
    "    error_val.append(error_val_i)\n",
    "    \n",
    "    #Choose the best lambda to be the one that minimizes the validation error\n",
    "    ind = np.argmin(error_val)\n",
    "        \n",
    "    return error_train, error_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79ac61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,theta,learn_rate,num_iters,Lambda):\n",
    "    \"\"\"\n",
    "    Take in numpy array X, y and theta and update theta by taking num_iters gradient steps\n",
    "    with learning rate of alpha\n",
    "    \n",
    "    return theta and the list of the cost of theta during each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    J_history =[]\n",
    "    for i in range(num_iters):\n",
    "        cost, grad = linearRegCostFunction(X,y,theta,Lambda)\n",
    "        theta = theta - (learn_rate * grad)\n",
    "        J_history.append(cost)\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0bfed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 50000\n",
      "\n",
      "Columns: 2\n",
      "Number of training days: 1\n",
      "Testing error: 0.00038188539213707964\n",
      "\n",
      "Columns: 3\n",
      "Number of training days: 2\n",
      "Testing error: 0.00047131095356671876\n",
      "\n",
      "Columns: 4\n",
      "Number of training days: 3\n",
      "Testing error: 0.0005272499329352024\n",
      "\n",
      "Columns: 5\n",
      "Number of training days: 4\n",
      "Testing error: 0.0005701076675469358\n",
      "\n",
      "Columns: 6\n",
      "Number of training days: 5\n",
      "Testing error: 0.0006196047091372425\n",
      "\n",
      "Columns: 7\n",
      "Number of training days: 6\n",
      "Testing error: 0.0006978975395869201\n",
      "\n",
      "Smallest error: (0.00038188539213707964, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Columns we want to try\n",
    "cols = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Parameters of the iterations\n",
    "num_iter = 50000\n",
    "Lambda = 0\n",
    "learn_rate = 0.001\n",
    "print('Number of iterations: ' + str(num_iter) + '\\n')\n",
    "\n",
    "minError = (1, 0)\n",
    "\n",
    "# Variable lists\n",
    "J_history_ls = []\n",
    "error_train_ls = []\n",
    "error_val_ls = []\n",
    "error_train_validation_ls = []\n",
    "error_val_validation_ls = []\n",
    "testing_num = 0\n",
    "\n",
    "# Iterate through all the columns\n",
    "for col in cols:\n",
    "   \n",
    "    # Resize the text file with the correct number of columns\n",
    "    divider, testing_num = resize_data_file(col)\n",
    "\n",
    "    # Read each text file\n",
    "    training_data = pd.read_csv('../Dataset/training_data.txt', header=None)\n",
    "    validation_data = pd.read_csv('../Dataset/validation_data.txt', header=None)\n",
    "    testing_data = pd.read_csv('../Dataset/testing_data.txt', header=None)\n",
    "\n",
    "    # Parse data\n",
    "    training_data = training_data.values\n",
    "    validation_data = validation_data.values\n",
    "    testing_data = testing_data.values\n",
    "    \n",
    "    # Training data\n",
    "    X = training_data[:, :(col - 1)]\n",
    "    y = training_data[:, (col - 1)]\n",
    "    y = y.reshape((len(y), 1))\n",
    "    m = len(y)\n",
    "    X_1 = np.append(np.ones((m,1)), X, axis=1)\n",
    "    \n",
    "    # Validation data\n",
    "    Xval = validation_data[:, :(col - 1)]\n",
    "    yval = validation_data[:, (col - 1)]\n",
    "    yval = yval.reshape((len(yval), 1))\n",
    "    mval = len(yval)\n",
    "    Xval_1 = np.append(np.ones((mval,1)), Xval, axis=1)\n",
    "    \n",
    "    # Testing data\n",
    "    Xtest = testing_data[:, :(col - 1)]\n",
    "    ytest = testing_data[:, (col - 1)]\n",
    "    ytest = ytest.reshape((len(ytest), 1))\n",
    "    mtest = len(ytest)\n",
    "    Xtest_1 = np.append(np.ones((mtest,1)), Xtest, axis=1)\n",
    "    \n",
    "    # Initialize all theta at 0. \n",
    "    initial_theta = np.zeros((X.shape[1] + 1, 1))\n",
    "\n",
    "    theta, J_history = gradientDescent(X_1,y,initial_theta,learn_rate,num_iter,Lambda)\n",
    "    J_history_ls.append(J_history)\n",
    "    \n",
    "    # Learning curve\n",
    "    mval = Xval.shape[0]  # Number of validation examples \n",
    "    Xval_1 = np.append(np.ones((mval,1)),Xval,axis=1)\n",
    "\n",
    "    # Validation curve\n",
    "\n",
    "    error_train_validation, error_val_validation = validationCurve(X, y, Xval, yval, learn_rate, 1)\n",
    "    error_train_validation_ls.append(error_train_validation)\n",
    "    error_val_validation_ls.append(error_val_validation)\n",
    "\n",
    "    # Initialize all theta at 0. \n",
    "    theta_ini = np.zeros((X.shape[1], 1))\n",
    "    theta_poly = gradientDescent(X, y,theta_ini,learn_rate,num_iter,0)[0]\n",
    "    \n",
    "    pred = np.dot(X,theta_poly)\n",
    "    Etrain = 1/(2*m) * np.sum((pred - y)**2)\n",
    "\n",
    "    pred_val = np.dot(Xval,theta_poly)\n",
    "    Eval = 1/(2*mval) * np.sum((pred_val - yval)**2)\n",
    "    \n",
    "    pred_test = np.dot(Xtest, theta_poly)\n",
    "    Etest = 1/(2*mtest) * np.sum((pred_test - ytest)**2)\n",
    "    \n",
    "    print('Columns: ' + str(col))\n",
    "\n",
    "    print('Number of training days: ' + str(col - 1))\n",
    "    print('Testing error: ' + str(Etest) + '\\n')\n",
    "    \n",
    "    if Etest < minError[0]:\n",
    "        minError = (Etest, col-1)\n",
    "print('Smallest error: ' + str(minError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60a369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Regularized cost function using gradient descent')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in J_history_ls:\n",
    "    plt.plot(j)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"$J(\\Theta)$\")\n",
    "plt.title(\"Regularized cost function using gradient descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ae87a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x205a4d022e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cols,error_train_validation_ls,label=\"Train\")\n",
    "plt.plot(cols,error_val_validation_ls,label=\"Cross Validation\",color=\"r\")\n",
    "plt.xlabel(\"Columns number\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181469b8",
   "metadata": {},
   "source": [
    "### As we can see, the best number of columns to use is 4, meaning we will use the price of the last 3 days to calculate the price for tomorrow (or in more days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029e94b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With normal price training:\n",
      "h(x) = 0.0112 + 0.2545x + 0.318x2 + 0.4104x3\n",
      "\n",
      "With price difference training:\n",
      "h(x) = 0.0021 + 0.055x + -0.0448x2\n"
     ]
    }
   ],
   "source": [
    "best_col = 4\n",
    "\n",
    "J_history_ls = []\n",
    "J_history_diff_ls = []\n",
    "\n",
    "# Resize for best column number\n",
    "resize_data_file(best_col)\n",
    "# For the diff\n",
    "scalar_val = resize_diff_file(best_col - 1)\n",
    "\n",
    "# Read the data again\n",
    "training_data = pd.read_csv('../Dataset/training_data.txt', header=None)\n",
    "training_data_diff = pd.read_csv('../Dataset/training_diff.txt', header=None)\n",
    "\n",
    "# Parse data\n",
    "training_data = training_data.values\n",
    "training_data_diff = training_data_diff.values\n",
    "    \n",
    "# Training data\n",
    "X = training_data[:, :(best_col - 1)]\n",
    "y = training_data[:, (best_col - 1)]\n",
    "y = y.reshape((len(y), 1))\n",
    "m = len(y)\n",
    "X_1 = np.append(np.ones((m,1)), X, axis=1)\n",
    "\n",
    "# Training data from the differences\n",
    "X_diff = training_data_diff[:, :(best_col - 2)]\n",
    "y_diff = training_data_diff[:, (best_col - 2)]\n",
    "y_diff = y_diff.reshape((len(y_diff), 1))\n",
    "m_diff = len(y_diff)\n",
    "X_1_diff = np.append(np.ones((m_diff,1)), X_diff, axis=1)\n",
    "\n",
    "# Gradient Descent with more iterations\n",
    "Lambda = 0\n",
    "learn_rate = 0.001\n",
    "num_iter = 300000\n",
    "\n",
    "# Initialize all theta at 0. \n",
    "initial_theta = np.zeros((X.shape[1] + 1, 1))\n",
    "initial_theta_diff = np.zeros((X_diff.shape[1] + 1, 1))\n",
    "\n",
    "print('With normal price training:')\n",
    "theta, J_history = gradientDescent(X_1, y, initial_theta, learn_rate, num_iter, Lambda)\n",
    "J_history_ls.append(J_history)\n",
    "print('h(x) = ' + str(round(theta[0,0], 4)) + ' + ' + str(round(theta[1,0], 4)) + 'x + ' + \\\n",
    "      str(round(theta[2,0], 4)) + 'x2 + ' + str(round(theta[3,0], 4)) + 'x3')\n",
    "\n",
    "print('\\nWith price difference training:')\n",
    "theta_diff, J_history_diff = gradientDescent(X_1_diff, y_diff, initial_theta_diff, learn_rate, num_iter, Lambda)\n",
    "J_history_diff_ls.append(J_history_diff)\n",
    "print('h(x) = ' + str(round(theta_diff[0,0], 4)) + ' + ' + str(round(theta_diff[1,0], 4)) + 'x + ' + \\\n",
    "      str(round(theta_diff[2,0], 4)) + 'x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fca0be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from the previous prices\n",
    "def predict(x, theta):\n",
    "    h = np.dot(x, theta)\n",
    "    return h[0]\n",
    "\n",
    "def predictInNDays(x, theta, days):\n",
    "    if days < 1:\n",
    "        return x[0]\n",
    "    elif days == 1:\n",
    "        return predict(x, theta) \n",
    "    else:\n",
    "        final_x = predict(x, theta)\n",
    "        # Each day becomes the day before\n",
    "        for i in range(1, len(x) - 1):\n",
    "            x[i] = x[i + 1]\n",
    "        x[len(x) - 1] = final_x\n",
    "        return predictInNDays(x, theta, days - 1)\n",
    "\n",
    "# Predict from the differences\n",
    "def predictDiff(x, theta):\n",
    "    h = np.dot(x, theta)\n",
    "    return h[0]\n",
    "\n",
    "def predictDiffInNDays(x, theta, days):\n",
    "    if days < 1:\n",
    "        return x[0]\n",
    "    elif days == 1:\n",
    "        return predictDiff(x, theta) \n",
    "    else:\n",
    "        final_x = predictDiff(x, theta)\n",
    "        # Each day becomes the day before\n",
    "        for i in range(1, len(x) - 1):\n",
    "            x[i] = x[i + 1]\n",
    "        x[len(x) - 1] = final_x\n",
    "        \n",
    "        return predictDiffInNDays(x, theta, days - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f3971",
   "metadata": {},
   "source": [
    "##  In the next cell, the user can choose:\n",
    "#### - The price values of the last days\n",
    "#### - The number of days from now to predict the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ca4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the price of the last two days\n",
    "price_2_days_ago = 41758.73\n",
    "price_yesterday = 43611.23\n",
    "price_today = 44303.08\n",
    "\n",
    "# Number of days from now, we want to predict the value (1 if tomorrow)\n",
    "days_from_now = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28714afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price in 1 day(s) with price data: 43354.59\n",
      "Price in 1 day(s) with differece data: 44437.38\n",
      "Final price in 1 day(s): 43895.98\n"
     ]
    }
   ],
   "source": [
    "# Calculate the differences\n",
    "diff1, diff2 = price_yesterday - price_2_days_ago, price_today - price_yesterday\n",
    "\n",
    "x_sample = [(price_2_days_ago/divider), (price_yesterday/divider), (price_today/divider)]\n",
    "x_sample = np.append(1, x_sample)\n",
    "\n",
    "x_sample_diff = [(diff1/scalar_val), (diff2/scalar_val)]\n",
    "x_sample_diff = np.append(1, x_sample_diff)\n",
    "\n",
    "pre = predictInNDays(x_sample, theta, days_from_now) \n",
    "pre_diff = predictDiffInNDays(x_sample_diff, theta_diff, days_from_now)\n",
    "\n",
    "price = round(pre * divider, 2)\n",
    "diff_price = round(price_today + pre_diff * scalar_val, 2)\n",
    "\n",
    "print('Price in ' + str(days_from_now) + ' day(s) with price data: ' + str(price) + '')\n",
    "print('Price in ' + str(days_from_now) + ' day(s) with differece data: ' + str(diff_price) + '')\n",
    "\n",
    "# Final price prediction\n",
    "final_price = round((price + diff_price) / 2, 2)\n",
    "print('Final price in ' + str(days_from_now) + ' day(s): ' + str(final_price) + '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d968a",
   "metadata": {},
   "source": [
    "### Now we proceed to compute the error of the 2 features, and the final predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the errors\n",
    "num_iter = 50000\n",
    "\n",
    "# Normal data values\n",
    "testing_data = pd.read_csv('../Dataset/testing_data.txt', header=None)\n",
    "testing_data = testing_data.values\n",
    "\n",
    "Xtest = testing_data[:, :(best_col - 1)]\n",
    "ytest = testing_data[:, (best_col - 1)]\n",
    "ytest = ytest.reshape((len(ytest), 1))\n",
    "mtest = len(ytest)\n",
    "Xtest_1 = np.append(np.ones((mtest,1)), Xtest, axis=1)\n",
    "\n",
    "theta_ini = np.zeros((X.shape[1], 1))\n",
    "theta_poly = gradientDescent(X, y,theta_ini,learn_rate,num_iter,0)[0]\n",
    "    \n",
    "pred_test = np.dot(Xtest, theta_poly)\n",
    "Etest = 1/(2*mtest) * np.sum((pred_test - ytest)**2)\n",
    "\n",
    "print('Testing error for normal data training: ' + str(Etest))\n",
    "\n",
    "# Difference data values\n",
    "testing_data_diff = pd.read_csv('../Dataset/testing_diff.txt', header=None)\n",
    "testing_data_diff = testing_data_diff.values\n",
    "\n",
    "Xtest_diff = testing_data_diff[:, :(best_col - 2)]\n",
    "ytest_diff = testing_data_diff[:, (best_col - 2)]\n",
    "ytest_diff = ytest_diff.reshape((len(ytest_diff), 1))\n",
    "mtest_diff = len(ytest_diff)\n",
    "Xtest_1_diff = np.append(np.ones((mtest_diff,1)), Xtest_diff, axis=1)\n",
    "\n",
    "theta_ini_diff = np.zeros((X_diff.shape[1], 1))\n",
    "theta_poly_diff = gradientDescent(X_diff, y_diff,theta_ini_diff,learn_rate,num_iter,0)[0]\n",
    "\n",
    "last_X_value = testing_data[:, (best_col - 2)]\n",
    "\n",
    "pred_test_diff = np.dot(Xtest_diff, theta_poly_diff)\n",
    "\n",
    "pred_test_diff_ls = []\n",
    "for i in pred_test_diff * scalar_val:\n",
    "    pred_test_diff_ls.append(i[0])\n",
    "\n",
    "pred_test_diff_final = (last_X_value * divider + pred_test_diff_ls) / 60000\n",
    "pred_test_diff_final = pred_test_diff_final.reshape((len(pred_test_diff_final), 1))\n",
    "\n",
    "Etest_diff = 1/(2*mtest) * np.sum((pred_test_diff_final - ytest)**2)\n",
    "\n",
    "print('Testing error for difference data training: ' + str(Etest_diff))\n",
    "\n",
    "# For the average of the 2 features\n",
    "average = (pred_test_diff_final + pred_test) / 2\n",
    "\n",
    "Etest_average = 1/(2*mtest) * np.sum((average - ytest)**2)\n",
    "\n",
    "print('Testing error for the average of the 2 features: ' + str(Etest_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphic of the Bitcoin prics vs predicted price\n",
    "arr_graph = pd.read_csv('../Dataset/btc_data.txt', header=None)\n",
    "arr_graph = arr_graph.values\n",
    "arr_graph = arr_graph[len(arr_graph) - testing_num:]\n",
    "y_real = [] \n",
    "\n",
    "for i in arr_graph:\n",
    "    y_real.append(i[0])\n",
    "\n",
    "\n",
    "x_real = list(range(0, len(arr_graph)))\n",
    "x_predicted = list(range(best_col - 1, len(arr_graph)))\n",
    "\n",
    "i = 0\n",
    "y_predicted = []\n",
    "for i in range(best_col - 1, len(arr_graph)):\n",
    "    price_2_days_ago = arr_graph[i-3]\n",
    "    price_yesterday = arr_graph[i-2]\n",
    "    price_today = arr_graph[i-1]\n",
    "    \n",
    "    x_sample = [(price_2_days_ago/divider), (price_yesterday/divider), (price_today/divider)]\n",
    "    x_sample = np.append(1, x_sample)\n",
    "\n",
    "    # Number of days from now, we want to predict the value (1 if tomorrow)\n",
    "    days_from_now = 1\n",
    "\n",
    "    pre = predictInNDays(x_sample, theta, days_from_now) \n",
    "\n",
    "    price = round(pre * divider, 2)\n",
    "    y_predicted.append(price)\n",
    "    \n",
    "plt.plot(x_predicted, y_predicted)\n",
    "plt.plot(x_real, y_real)\n",
    "plt.legend([\"Predicted Values\", \"Real Values\"], loc =\"lower right\")\n",
    "plt.title(\"Real Price vs Predicted Price of testing data (Based on last three days)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphic of the Bitcoin prics vs predicted price using differences\n",
    "\n",
    "x_predicted_diff = list(range(best_col - 1, len(arr_graph)))\n",
    "\n",
    "i = 0\n",
    "y_predicted_diff = []\n",
    "\n",
    "for i in range(best_col - 1, len(arr_graph)):\n",
    "    \n",
    "    # 3 days\n",
    "    price_2_days_ago = arr_graph[i-3]\n",
    "    price_yesterday = arr_graph[i-2]\n",
    "    price_today = arr_graph[i-1]\n",
    "    \n",
    "    # 2 differences\n",
    "    diff1, diff2 = price_yesterday - price_2_days_ago, price_today - price_yesterday\n",
    "    \n",
    "    x_sample_diff = [(diff1 / scalar_val), (diff2 / scalar_val)]\n",
    "    x_sample_diff = np.append(1, x_sample_diff)\n",
    "    \n",
    "    # Number of days from now, we want to predict the value (1 if tomorrow)\n",
    "    days_from_now = 1\n",
    "\n",
    "    pre = predictDiffInNDays(x_sample_diff, theta_diff, days_from_now)\n",
    "    \n",
    "    diff_price = price_today + pre * scalar_val\n",
    "    \n",
    "    y_predicted_diff.append(round(diff_price[0], 2))\n",
    "    \n",
    "plt.plot(x_predicted_diff, y_predicted_diff)\n",
    "plt.plot(x_real, y_real)\n",
    "\n",
    "plt.legend([\"Predicted Values\", \"Real Values\"], loc =\"lower right\")\n",
    "plt.title(\"Real Price vs Predicted Price of testing data using differences\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Predicted price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba278713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final graphic of the Bitcoin prics vs predicted price using the mean of the previous features\n",
    "y_predicted_final = []\n",
    "i = 0\n",
    "for val in y_predicted_diff:\n",
    "    y_predicted_final.append(round((val + y_predicted[i]) / 2, 2))\n",
    "    i += 1\n",
    "    \n",
    "plt.plot(x_predicted_diff, y_predicted_final)\n",
    "plt.plot(x_real, y_real)\n",
    "\n",
    "plt.legend([\"Predicted Values\", \"Real Values\"], loc =\"lower right\")\n",
    "plt.title(\"Real Price vs Predicted Price of testing data Final (Based on last three days)\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Predicted price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279689e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
